{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ship Detection\n\n## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport gc\nimport math\nimport matplotlib.pyplot as plt \nfrom PIL import Image\nfrom mpl_toolkits.axes_grid1 import AxesGrid\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical \nfrom keras import backend as K \nfrom keras import models, layers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nimport tensorflow_probability as tfp\nimport tensorflow as tf\ntf.config.run_functions_eagerly(True) # https://github.com/tensorflow/tensorflow/issues/34983\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constants","metadata":{}},{"cell_type":"code","source":"ORIGINAL_IMAGE_DIMENSION = 768","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"# Loads the metadata file with the ship segmentations and adds an extra column which indicates whether the image has any ships in it or not.\n# Returns a dataframe\ndef load_metadata():\n    df = pd.read_csv(os.path.join(\"..\", \"input\", \"airbus-ship-detection\", \"train_ship_segmentations_v2.csv\"))\n    df = df.groupby([\"ImageId\"]).agg(lambda x: x.dropna().tolist())\\\n        .reset_index()\n    df[\"HasShips\"] = np.where(df['EncodedPixels'].str.len() > 0, 1, 0)\n    df[\"NumberOfShips\"] = df[\"EncodedPixels\"].str.len()\n    df.set_index(\"ImageId\", inplace=True)\n    return df   \n\ndef get_preprocessed_image(df_row, dimension=ORIGINAL_IMAGE_DIMENSION, from_training_directory=True):\n    img = load_image(df_row[\"ImageId\"], from_training_directory=from_training_directory)\n    img = preprocess_image(img, dimension)\n    return img\n\n# Loads an image as MxNx3 array by the imageId.\ndef load_image(imageId, from_training_directory = True):\n    subfolder = \"train_v2\" if from_training_directory else \"test_v2\"\n    imagePath = os.path.join(\"..\", \"input\", \"airbus-ship-detection\", subfolder, imageId)\n    return cv2.imread(imagePath)\n\n# Resizing and scaling of the image\ndef preprocess_image(image, dimension=ORIGINAL_IMAGE_DIMENSION):\n    return cv2.resize(image, (dimension, dimension)).astype('float32') / 255.\n\ndef get_mask_as_image(df_row, dimension=ORIGINAL_IMAGE_DIMENSION):\n    all_masks = np.zeros((ORIGINAL_IMAGE_DIMENSION, ORIGINAL_IMAGE_DIMENSION))\n    for mask in df_row[\"EncodedPixels\"]:\n        all_masks += rle_decode(mask, ORIGINAL_IMAGE_DIMENSION)\n    return cv2.resize(all_masks, (dimension, dimension))\n\ndef cleanup():\n    K.clear_session()\n    gc.collect()\n\n# Plots a list of images. Optionaly a list of masks can be provided\ndef plot_images(images, masks = None):\n    cols = 4\n    rows = math.ceil(len(images) / 4)\n    figure = plt.figure(1, (15,20))\n    grid = AxesGrid(figure, 111, nrows_ncols=(rows, cols), axes_pad=0, label_mode=\"1\")\n    \n    for index, image in enumerate(images):\n        grid[index].imshow(image[...,::-1]) # RGB-> BGR\n        if masks is not None and masks.ndim == 3 and masks.shape[0] > index:\n            grid[index].imshow(masks[index,:,:], cmap=\"cool\", alpha=masks[index,:,:]*0.45)\n\ndef plot_model_fitting_history(history):\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,2,(1))\n    plt.plot(history.history['accuracy'],linestyle='-.')\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='lower right')\n    plt.subplot(1,2,(2))\n    plt.plot(history.history['loss'],linestyle='-.')\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='upper right')\n    \n# Samples the dataframe but tries to keep it balanced / stratified\ndef sample_and_split(df, stratify_column, test_size, sample_size):\n    number_of_groups = len(df[stratify_column].unique())\n    samples_per_group = int(sample_size / number_of_groups)\n    balanced_df = df.groupby(stratify_column)\\\n        .apply(lambda x: x.sample(samples_per_group) if len(x) > samples_per_group else x)\\\n        .droplevel(0)\\\n        .reset_index()\n    return train_test_split(balanced_df, test_size = test_size, stratify = balanced_df[stratify_column])\n\n# Generic data generater that can be used to load the images in batches to avoid OOM errors and loads random samples\ndef random_data_generator(df, get_X, get_y, batch_size):\n    X = []\n    y = []\n    \n    while True:\n        row = df.sample(n=1).iloc[0]\n        X += [get_X(row)]\n        y += [get_y(row)]\n        if len(X) >= batch_size:\n            yield np.array(X), np.array(y)\n            X.clear()\n            y.clear()\n            \n# Generic data generater that can be used to load the images in batches to avoid OOM errors\ndef data_generator(df, get_X, get_y, batch_size):\n    X = []\n    y = []\n    \n    while True:\n        for index, row in df.iterrows():\n            X += [get_X(row)]\n            y += [get_y(row)]\n            if len(X) >= batch_size:\n                yield np.array(X), np.array(y)\n                X.clear()\n                y.clear()\n\n# Run lenght encoding of an encoded mask string.\n# Returns a 2 dimensional array with 0 or 1 in it\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, dimension=ORIGINAL_IMAGE_DIMENSION):\n    mask = np.zeros(dimension * dimension, dtype=np.uint8)\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    \n    for lo, hi in zip(starts, ends):\n        mask[lo:hi] = 1\n    return mask.reshape(dimension, dimension).T\n\n## calculate intersection over union\ndef calculate_jaccard_coefficient_keras(y_true, y_pred, eps=1e-6):\n    if np.max(y_true) == 0.0:\n        return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros\n    intersection = K.sum(y_true * y_pred, axis=[1,2])\n    union = K.sum(y_true, axis=[1,2]) + K.sum(y_pred, axis=[1,2]) - intersection\n    return -K.mean( (intersection + eps) / (union + eps), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploration","metadata":{}},{"cell_type":"code","source":"df_metadata = load_metadata()\ndf_metadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of images: \" + str(df_metadata.shape[0]))\nprint(\"Images with ships:       \" + str(df_metadata[\"HasShips\"].values.sum()))\nprint(\"Minimum number of ships:\" + str(df_metadata[\"NumberOfShips\"].min()))\nprint(\"Maximum number of ships:\" + str(df_metadata[\"NumberOfShips\"].max()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pie Chart","metadata":{}},{"cell_type":"code","source":"ships = sum(df_metadata[\"HasShips\"] == 1) # Number of Ships\nnships = sum(df_metadata[\"HasShips\"] == 0) # Number without Ships\ntotal = ships + nships\nships_p = round(ships/(total)*100)\nnships_p = round(nships/(total)*100)\n                 \nlabels = \"Images with ships\", \"Images without ships\"\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots(figsize=(15, 10))\nax1.pie([ships_p, nships_p], explode=explode, labels=labels, autopct='%1.1f%%', textprops={'fontsize': 15})\nax1.axis('equal')\nplt.title('Proportion of Images with Ships', fontweight = 'bold', fontsize = 15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bar Plot","metadata":{}},{"cell_type":"code","source":"df_metadata[\"NumberOfShips\"].plot(kind=\"hist\", title =\"Histogram of Number of Ships\", figsize=(15, 10), bins=len(df_metadata[\"NumberOfShips\"].unique()))\nplt.xlabel('Number of Ships per Image', fontsize = 15)\nplt.ylabel('Frequency [log]', fontsize = 15)\nplt.yscale('log')\nplt.title('Bar Chart with Number of Ships', fontweight = 'bold', fontsize = 15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RGB Histogram of every 20th Image","metadata":{}},{"cell_type":"code","source":"# Lasts ca. 8 MINUTES (without GPU)\nimport matplotlib.ticker as ticker\n\nnb_bins = 256\ncount_r = np.zeros(nb_bins)\ncount_g = np.zeros(nb_bins)\ncount_b = np.zeros(nb_bins)\n\nfor image in os.listdir('../input/airbus-ship-detection/train_v2')[::20]:\n  img = Image.open('../input/airbus-ship-detection/train_v2/'+image)\n  x = np.array(img)\n  x = x.transpose(2, 0, 1)\n  hist_r = np.histogram(x[0], bins=nb_bins, range=[0, 255])\n  hist_g = np.histogram(x[1], bins=nb_bins, range=[0, 255])\n  hist_b = np.histogram(x[2], bins=nb_bins, range=[0, 255])\n  count_r += hist_r[0]\n  count_g += hist_g[0]\n  count_b += hist_b[0]\n\nbins = hist_r[1]\nfig, ax = plt.subplots(figsize=(15, 10))  \nplt.bar(bins[:-1], count_r, color='r', alpha=0.7)\nplt.bar(bins[:-1], count_g, color='g', alpha=0.7)\nplt.bar(bins[:-1], count_b, color='b', alpha=0.7)\nplt.xlabel('Pixel Brightness', fontsize = 15)\nplt.ylabel('Number of Pixels', fontsize = 15)\nplt.yticks(rotation=45)\nplt.ticklabel_format(style = 'plain', useLocale = True) \nax.yaxis.set_major_formatter(ticker.EngFormatter())\nplt.title('RGB Histogram of every 20th Image', fontweight = 'bold', fontsize = 15)\nplt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Example Image with Mask","metadata":{}},{"cell_type":"code","source":"row = df_metadata.reset_index().iloc[15]\nimg = get_preprocessed_image(row)\nmask = get_mask_as_image(row)\nplot_images([img, img], np.array([mask]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Ship Detection\n\nDetect whether there is a ship in the image or not","metadata":{}},{"cell_type":"code","source":"# split into test and trainings data set\ndf_train, df_test = train_test_split(df_metadata, test_size = 0.20, stratify = df_metadata[\"NumberOfShips\"])\n# split further into trainings/validation data set\n\n# df_train = df_train.sample(100000) # but reduce dataset size\n# df_train, df_validation = train_test_split(df_train,\n#                                          stratify=df_train[\"HasShips\"],\n#                                          test_size=0.25)\n\n# split and balance trainings/validation data set\ndf_train, df_validation = sample_and_split(df_train,\n                                          stratify_column=\"HasShips\",\n                                          test_size=0.25,\n                                          sample_size=100000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SKIP_TRAINING_AND_LOAD_WEIGHTS = True\n\n# Hyper Parameters #\nBATCH_SIZE = 48\nMAX_TRAINING_STEPS = 1000\nCLASSES = 2\nEPOCHS = 10\nIMG_DIMENSION = 256\nINPUT_SHAPE = (IMG_DIMENSION, IMG_DIMENSION, 3)\nKERNEL_SIZE = (5, 5)\nPOOL_SIZE = (2, 2)\nSTEPS_PER_EPOCH = min(MAX_TRAINING_STEPS, df_train.shape[0]//BATCH_SIZE)\nVALIDATION_STEPS = 100\n\n\ntrainings_generator = data_generator(df_train.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                  get_y= lambda row: to_categorical(row[\"HasShips\"], CLASSES),\n                                  batch_size = BATCH_SIZE)\nvalidation_generator = random_data_generator(df_validation.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                  get_y= lambda row: to_categorical(row[\"HasShips\"],  CLASSES),\n                                  batch_size = BATCH_SIZE)\n\n# create model\nmodel = models.Sequential()\n\nmodel.add(layers.Convolution2D(8,KERNEL_SIZE,padding='same',input_shape=INPUT_SHAPE))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Convolution2D(8, KERNEL_SIZE,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=POOL_SIZE))\n\nmodel.add(layers.Convolution2D(16, KERNEL_SIZE,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\n\nmodel.add(layers.Convolution2D(16,KERNEL_SIZE,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=POOL_SIZE))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(40))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dense(CLASSES))\nmodel.add(layers.Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nif SKIP_TRAINING_AND_LOAD_WEIGHTS:\n    model.load_weights(os.path.join(\"..\", \"input\", \"airbusshipdetectionmodels\", \"simple_model_10e_sampled.h5\"))\nelse:\n    # train the model\n    history=model.fit(trainings_generator, \n                      validation_data=validation_generator,\n                      epochs=EPOCHS,\n                      steps_per_epoch=STEPS_PER_EPOCH,\n                      validation_steps=VALIDATION_STEPS,\n                      verbose=1)\n    model.save_weights(\"simple_model.h5\")\n    plot_model_fitting_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation with Test Set","metadata":{}},{"cell_type":"code","source":"test_generator = random_data_generator(df_test.reset_index(), \n                                      get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                      get_y= lambda row: to_categorical(row[\"HasShips\"], CLASSES),\n                                      batch_size = 1000)\n\n# predict random 1000 samples (the whole test data set takes too much time)\nX_test, y_test = next(test_generator)\ny_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n', classification_report(np.where(y_test > 0)[1], \nnp.argmax(y_pred, axis=1)), sep='')                                        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncnf_matrix = confusion_matrix(np.where(y_test > 0)[1], np.argmax(y_pred, axis=1))\nclass_labels = list([\"no-ship\", \"ship\"])\nplt.imshow(cnf_matrix, interpolation='nearest')\nplt.colorbar()\ntick_marks = np.arange(CLASSES)\n_ = plt.xticks(tick_marks, class_labels, rotation=90)\n_ = plt.yticks(tick_marks, class_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multinomial Classifcation\nDetect wheter there is no ship, one, two or more ships in the image\n","metadata":{}},{"cell_type":"code","source":"df_metadata[\"NumerOfShips0to3\"]= df_metadata.apply(lambda x: 3 if x[\"NumberOfShips\"] >= 3 else x[\"NumberOfShips\"], axis=1)  \ndf_metadata[\"NumerOfShips0to3\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SKIP_TRAINING_AND_LOAD_WEIGHTS = True\n\n# here we define  hyperparameter of the NN\nbatch_size = 48\nmax_training_steps = 1000\nclasses = 4\nepochs = 10\nimg_dimension = 256\nkernel_size = (5, 5)\ninput_shape = (img_dimension, img_dimension, 3)\npool_size = (2, 2)\n\n# split into test and trainings data set\ndf_train, df_test = train_test_split(df_metadata, test_size = 0.25, stratify = df_metadata[\"NumerOfShips0to3\"])\n# split and balance trainings/validation data set\ndf_train, df_validation = sample_and_split(df_train,\n                                          stratify_column=\"NumerOfShips0to3\",\n                                          test_size=1/3,\n                                          sample_size=40000)\n\n\nsteps_per_epoch = min(max_training_steps, df_train.shape[0]//batch_size)\ntrainings_generator = data_generator(df_train.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, img_dimension)),\n                                  get_y= lambda row: to_categorical(row[\"NumerOfShips0to3\"], classes),\n                                  batch_size = batch_size)\nvalidation_generator = random_data_generator(df_validation.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, img_dimension)),\n                                  get_y= lambda row: to_categorical(row[\"NumerOfShips0to3\"], classes),\n                                  batch_size = batch_size)\n\n# create model\nmodel = models.Sequential()\n\n#model.add(BatchNormalization(input_shape=input_shape))\nmodel.add(layers.Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Convolution2D(8, kernel_size,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=pool_size))\n\nmodel.add(layers.Convolution2D(16, kernel_size,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Convolution2D(16,kernel_size,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=pool_size))\n          \nmodel.add(layers.Convolution2D(64, kernel_size,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Convolution2D(64,kernel_size,padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=pool_size))          \n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(500))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(300))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(100))\nmodel.add(layers.Activation('relu'))\n\nmodel.add(layers.Dense(classes))\nmodel.add(layers.Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nif SKIP_TRAINING_AND_LOAD_WEIGHTS:\n    model.load_weights(os.path.join(\"..\", \"input\", \"airbusshipdetectionmodels\", \"multi_model_60.h5\"))\nelse:\n    # train the model\n    history=model.fit(trainings_generator, \n                      validation_data=validation_generator,\n                      epochs=epochs,\n                      steps_per_epoch=steps_per_epoch,\n                      validation_steps=100,\n                      verbose=1)\n    model.save_weights(\"multi_model.h5\")\n    plot_model_fitting_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = random_data_generator(df_test.reset_index(), \n                                      get_X= lambda row: np.array(get_preprocessed_image(row, img_dimension)), \n                                      get_y= lambda row: to_categorical(row[\"NumerOfShips0to3\"], classes),\n                                      batch_size = 1000)\n\n# predict 1000 samples\nX_test, y_test = next(test_generator)\ny_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n', classification_report(np.where(y_test > 0)[1], \n                                  np.argmax(y_pred, axis=1)), sep='')     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncnf_matrix = confusion_matrix(np.where(y_test > 0)[1], np.argmax(y_pred, axis=1), normalize='true')\nclass_labels = list([\"no-ship\", \"1 ship\", \"2 ship\", \">=3 ship\"])\nplt.imshow(cnf_matrix, interpolation='nearest')\nplt.colorbar()\ntick_marks = np.arange(classes)\n_ = plt.xticks(tick_marks, class_labels, rotation=90)\n_ = plt.yticks(tick_marks, class_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gaussian CPD\nCounting ships using Gaussian CPD (flexible mean & variance)","metadata":{}},{"cell_type":"markdown","source":"### !!!Continue with \"Image Segmentation\" or close the session and restart it with Gaussian CPD!!!","metadata":{}},{"cell_type":"markdown","source":"### Install old Version\nVersions like 2.4.1 and 0.8.0 are not able to calculate measures of position like \"mean\" and \"standard deviation\".","metadata":{}},{"cell_type":"code","source":"# Make sure you enabled \"internet connection\" on the right hand side\n!pip install tensorflow==2.1.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_probability==0.8.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport gc\nimport math\nimport matplotlib.pyplot as plt \nfrom mpl_toolkits.axes_grid1 import AxesGrid\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical \n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation, Dropout, Input, Concatenate\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\nfrom tensorflow.keras.models import Sequential\n\nimport tensorflow as tf\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Version","metadata":{}},{"cell_type":"code","source":"print(\"TF  Version\",tf.__version__)\nprint(\"TFP Version\", tfp.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Constants","metadata":{}},{"cell_type":"code","source":"ORIGINAL_IMAGE_DIMENSION = 768","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"# Loads the metadata file with the ship segmentations and adds an extra column which indicates whether the image has any ships in it or not.\n# Returns a dataframe\ndef load_metadata():\n    df = pd.read_csv(os.path.join(\"..\", \"input\", \"airbus-ship-detection\", \"train_ship_segmentations_v2.csv\"))\n    df = df.groupby([\"ImageId\"]).agg(lambda x: x.dropna().tolist())\\\n        .reset_index()\n    df[\"HasShips\"] = np.where(df['EncodedPixels'].str.len() > 0, 1, 0)\n    df[\"NumberOfShips\"] = df[\"EncodedPixels\"].str.len()\n    df.set_index(\"ImageId\", inplace=True)\n    return df   \n\ndef get_preprocessed_image(df_row, dimension=ORIGINAL_IMAGE_DIMENSION):\n    img = load_image(df_row[\"ImageId\"], from_training_directory=True)\n    img = preprocess_image(img, dimension)\n    return img\n\n# Loads an image as MxNx3 array by the imageId.\ndef load_image(imageId, from_training_directory = True):\n    subfolder = \"train_v2\" if from_training_directory else \"test_v2\"\n    imagePath = os.path.join(\"..\", \"input\", \"airbus-ship-detection\", subfolder, imageId)\n    return cv2.imread(imagePath)\n\n# Resizing and scaling of the image\ndef preprocess_image(image, dimension=ORIGINAL_IMAGE_DIMENSION):\n    return cv2.resize(image, (dimension, dimension)).astype('float32') / 255.\n\ndef get_mask_as_image(df_row, dimension=ORIGINAL_IMAGE_DIMENSION):\n    all_masks = np.zeros((ORIGINAL_IMAGE_DIMENSION, ORIGINAL_IMAGE_DIMENSION))\n    for mask in df_row[\"EncodedPixels\"]:\n        all_masks += rle_decode(mask)\n    return cv2.resize(all_masks, (dimension, dimension))\n\ndef cleanup():\n    K.clear_session()\n    gc.collect()\n\n# Plots a list of images. Optionaly a list of masks can be provided\ndef plot_images(images, masks = []):\n    cols = 4\n    rows = math.ceil(len(images) / 4)\n    figure = plt.figure(1, (15,20))\n    grid = AxesGrid(figure, 111, nrows_ncols=(rows, cols), axes_pad=0, label_mode=\"1\")\n    \n    for index, image in enumerate(images):\n        grid[index].imshow(image[...,::-1]) # RGB-> BGR\n        if len(masks) > index:\n            grid[index].imshow(masks[index], cmap=\"cool\", alpha=mask*0.65)\n\ndef plot_model_fitting_history(history):\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,2,(1))\n    plt.plot(history.history['accuracy'],linestyle='-.')\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='lower right')\n    plt.subplot(1,2,(2))\n    plt.plot(history.history['loss'],linestyle='-.')\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='upper right')\n    \n# Samples the dataframe but tries to keep it balanced / stratified\ndef sample_and_split(df, stratify_column, test_size, sample_size):\n    number_of_groups = len(df[stratify_column].unique())\n    samples_per_group = int(sample_size / number_of_groups)\n    balanced_df = df.groupby(stratify_column)\\\n        .apply(lambda x: x.sample(samples_per_group) if len(x) > samples_per_group else x)\\\n        .droplevel(0)\\\n        .reset_index()\n    return train_test_split(balanced_df, test_size = test_size, stratify = balanced_df[stratify_column])\n\n# Generic data generater that can be used to load the images in batches to avoid OOM errors and loads random samples\ndef random_data_generator(df, get_X, get_y, batch_size):\n    X = []\n    y = []\n    \n    while True:\n        row = df.sample(n=1).iloc[0]\n        X += [get_X(row)]\n        y += [get_y(row)]\n        if len(X) >= batch_size:\n            yield np.array(X), np.array(y)\n            X.clear()\n            y.clear()\n            \n# Generic data generater that can be used to load the images in batches to avoid OOM errors\ndef data_generator(df, get_X, get_y, batch_size):\n    X = []\n    y = []\n    \n    while True:\n        for index, row in df.iterrows():\n            X += [get_X(row)]\n            y += [get_y(row)]\n            if len(X) >= batch_size:\n                yield np.array(X), np.array(y)\n                X.clear()\n                y.clear()\n\n# Run lenght encoding of an encoded mask string.\n# Returns a 2 dimensional array with 0 or 1 in it\ndef rle_decode(mask_rle):\n    mask = np.zeros(ORIGINAL_IMAGE_DIMENSION * ORIGINAL_IMAGE_DIMENSION, dtype=np.uint8)\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    \n    for lo, hi in zip(starts, ends):\n        mask[lo:hi] = 1\n    return mask.reshape(ORIGINAL_IMAGE_DIMENSION, ORIGINAL_IMAGE_DIMENSION).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metadata","metadata":{}},{"cell_type":"code","source":"df_metadata = load_metadata()\ndf_metadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparation","metadata":{}},{"cell_type":"code","source":"df_metadata= df_metadata.loc[df_metadata[\"NumberOfShips\"] > 0] # at least one ship\n\n# split into test and trainings data set\ndf_train, df_test = train_test_split(df_metadata, test_size = 0.20, stratify = df_metadata[\"NumberOfShips\"])\n# split further into trainings/validation data set\n\n# df_train = df_train.sample(100000) # but reduce dataset size\n# df_train, df_validation = train_test_split(df_train,\n#                                          stratify=df_train[\"HasShips\"],\n#                                          test_size=0.25)\n\n# split and balance trainings/validation data set\ndf_train, df_validation = sample_and_split(df_train,\n                                          stratify_column=\"NumberOfShips\",\n                                          test_size=0.25,\n                                          sample_size=100000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nplt.hist(df_train[\"NumberOfShips\"],bins=30)\nplt.title(\"Number of Ships: train\")\nplt.subplot(1,2,2)\nplt.hist(df_validation[\"NumberOfShips\"],bins=30)\nplt.title(\"Number of Ships: val\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"SKIP_TRAINING_AND_LOAD_WEIGHTS = True\n\n# here we define hyperparameter of the NN\nBATCH_SIZE = 48\nMAX_TRAINING_STEPS = 1000\nEPOCHS = 15\nIMG_DIMENSION = 256\nINPUT_SHAPE = (IMG_DIMENSION, IMG_DIMENSION, 3)\nKERNEL_SIZE = (3, 3)\nPOOL_SIZE = (2, 2)\nSTEPS_PER_EPOCH = min(MAX_TRAINING_STEPS, df_train.shape[0]//BATCH_SIZE)\nVALIDATION_STEPS = 100\n\n# traininigs- /validation_generator\ntrainings_generator = data_generator(df_train.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                  get_y= lambda row: np.asarray(row[\"NumberOfShips\"]).astype(\"float32\"),\n                                  batch_size = BATCH_SIZE)\nvalidation_generator = random_data_generator(df_validation.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                  get_y= lambda row: np.asarray(row[\"NumberOfShips\"]).astype(\"float32\"),\n                                  batch_size = BATCH_SIZE)\n\n\n# model\ndef NLL(y, distr):\n  return -distr.log_prob(y) \n\ndef my_dist(params): \n  return tfd.Normal(loc=params[:,0:1], scale=1e-3 + tf.math.softplus(0.05 * params[:,1:2]))# both parameters are learnable\n\ninputs = Input(shape=(INPUT_SHAPE))\nx = Convolution2D(8,KERNEL_SIZE,padding='same',activation=\"relu\")(inputs)\nx = Convolution2D(8,KERNEL_SIZE,padding='same',activation=\"relu\")(x)\nx = MaxPooling2D(pool_size=POOL_SIZE)(x)\n\nx = Convolution2D(16,KERNEL_SIZE,padding='same',activation=\"relu\")(x)\nx = Convolution2D(16,KERNEL_SIZE,padding='same',activation=\"relu\")(x)\nx = MaxPooling2D(pool_size=POOL_SIZE)(x)\n\nx = Flatten()(x)\nx = Dropout(0.3)(x)\nx = Dense(256,activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(128,activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(64,activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(2)(x)\ndist = tfp.layers.DistributionLambda(my_dist)(x) \n\nmodel_flex = Model(inputs=inputs, outputs=dist)\nmodel_flex.compile(tf.keras.optimizers.Adam(), loss=NLL)\n\nif SKIP_TRAINING_AND_LOAD_WEIGHTS:\n    model_flex.load_weights(os.path.join(\"..\", \"input\", \"airbusshipdetectionmodels\", \"adv_model2.h5\"))\nelse:\n    # train the model\n    history=model_flex.fit(trainings_generator, \n                           validation_data=validation_generator,\n                           epochs=EPOCHS,\n                           steps_per_epoch=STEPS_PER_EPOCH,\n                           validation_steps=VALIDATION_STEPS,\n                           verbose=1)\n    model_flex.save_weights(\"adv_model2.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"markdown","source":"mean, standard deviation","metadata":{}},{"cell_type":"code","source":"model_mean = Model(inputs=inputs, outputs=dist.mean())\nmodel_sd = Model(inputs=inputs, outputs=dist.stddev())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict 1000 samples","metadata":{}},{"cell_type":"code","source":"test_generator = random_data_generator(df_test.reset_index(), \n                                       get_X= lambda row: np.array(get_preprocessed_image(row, IMG_DIMENSION)),\n                                       get_y= lambda row: np.asarray(row[\"NumberOfShips\"]).astype(\"float32\"),\n                                       batch_size = 1000)\n\n# predict 1000 samples\nX_test, y_test = next(trainings_generator)\ny_pred = model_flex.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at the predicted mean of the CPD on the testset","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i in range(0,25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(X_test[i])\n    plt.title(\"pred : \"+ np.str(model_mean.predict(X_test[i:i+1])[0][0]) + \"   true : \"+ np.str(y_test[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at the predicted mean and the predicted sigma of the CPD on the testset","metadata":{}},{"cell_type":"code","source":"for i in range(0,10):\n  plt.figure(figsize=(12,6))\n  plt.subplot(1,2,1)\n  plt.imshow(X_test[i])\n  plt.title(\"pred : \"+ np.str(model_mean.predict(X_test[i:i+1])[0][0]) + \"   true : \"+ np.str(y_test[i]))\n  print(model_mean.predict(X_test[i:i+1]))\n  print(model_sd.predict(X_test[i:i+1]))\n  d = tfd.Normal(loc=model_mean.predict(X_test[i:i+1]), scale=model_sd.predict(X_test[i:i+1]))           #A\n  plt.subplot(1,2,2)\n  plt.plot(np.arange(-10,100,0.2),d.prob(np.arange(-10,100,0.2))[0])\n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Indicator","metadata":{}},{"cell_type":"code","source":"mse=np.average(np.square(model_mean.predict(X_test).flatten()-y_test))\nrmse=np.sqrt(mse)\nnll=model_flex.evaluate(X_test,y_test,verbose=0)\ndf= pd.DataFrame(\n         { 'MSE' : mse, 'RMSE' : rmse, 'nll ' : nll}, index=['model flex sigma'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reload Metadata\n","metadata":{}},{"cell_type":"code","source":"df_metadata = load_metadata()\ndf_metadata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Segmentation\n\nDetect all the ships in an image with their bounding boxes","metadata":{"trusted":true}},{"cell_type":"code","source":"### split into test and trainings data set\ndf_train, df_test = train_test_split(df_metadata, test_size = 0.25, stratify = df_metadata[\"NumberOfShips\"])\n# split and balance trainings/validation data set\ndf_train, df_validation = sample_and_split(df_metadata,\n                                          stratify_column=\"NumberOfShips\",\n                                          test_size=0.5,\n                                          sample_size=10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SKIP_TRAINING_AND_LOAD_WEIGHTS = True\nWEIGHT_CHECKPOINT_PATH = \"{}_weights.best.hdf5\".format('seg_model')\n\n# Hyper Parameters #\nBATCH_SIZE = 24\nGAUSSIAN_NOISE = 0.1\nNET_SCALING = (1, 1) # optional downsampling inside the network (disabled)\nMAX_TRAINING_STEPS = 9\nMAX_TRAIN_EPOCHS = 99\nIMG_DIMENSION = 256\nINPUT_SHAPE = (IMG_DIMENSION, IMG_DIMENSION, 3)\nSTEPS_PER_EPOCH = min(MAX_TRAINING_STEPS, df_train.shape[0]//BATCH_SIZE)\nVALIDATION_STEPS = 100\n\ntrainings_generator = data_generator(df_train.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, dimension=IMG_DIMENSION)),\n                                  get_y= lambda row: np.array(get_mask_as_image(row, dimension=IMG_DIMENSION)),\n                                  batch_size = BATCH_SIZE)\nvalidation_generator = random_data_generator(df_validation.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, dimension=IMG_DIMENSION)),\n                                  get_y= lambda row: np.array(get_mask_as_image(row, dimension=IMG_DIMENSION)),\n                                  batch_size = BATCH_SIZE)\n\n# create model\ninput_img = layers.Input(INPUT_SHAPE, name = 'RGB_Input')\n\npp_in_layer = input_img\npp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\npp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\npp_in_layer = layers.BatchNormalization()(pp_in_layer)\n\nc1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\nc1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = layers.MaxPooling2D((2, 2)) (c1)\n\nc2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = layers.MaxPooling2D((2, 2)) (c2)\n\nc3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = layers.MaxPooling2D((2, 2)) (c3)\n\nc4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = layers.UpSampling2D((2, 2)) (c5)\nu6 = layers.concatenate([u6, c4])\nc6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = layers.UpSampling2D((2, 2)) (c6)\nu7 = layers.concatenate([u7, c3])\nc7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = layers.UpSampling2D((2, 2)) (c7)\nu8 = layers.concatenate([u8, c2])\nc8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = layers.UpSampling2D((2, 2)) (c8)\nu9 = layers.concatenate([u9, c1], axis=3)\nc9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\nd = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\nd = layers.UpSampling2D(NET_SCALING)(d)\n\nseg_model = models.Model(inputs=[input_img], outputs=[d])\n\n#seg_model.summary()\ntf.keras.utils.plot_model(seg_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks_list = [ModelCheckpoint(WEIGHT_CHECKPOINT_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True),\n                  EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=20), # probably needs to be more patient, but kaggle time is limited\n                  ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n                                    patience=1, verbose=1, mode='min',\n                                    min_delta=0.0001, cooldown=0, min_lr=1e-8)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit():\n    seg_model.compile(optimizer=Adam(1e-3, decay=1e-6), \n                      loss=calculate_jaccard_coefficient_keras, \n                      metrics=['binary_accuracy'])\n    loss_history = [seg_model.fit(trainings_generator,\n                                  validation_data = validation_generator,\n                                  validation_steps = STEPS_PER_EPOCH//2,\n                                  epochs = MAX_TRAIN_EPOCHS,\n                                  steps_per_epoch = STEPS_PER_EPOCH,\n                                  callbacks = callbacks_list, \n                                  workers = 1,\n                                  verbose = 1)]\n    \n    return loss_history\n\nif (SKIP_TRAINING_AND_LOAD_WEIGHTS):\n    seg_model.load_weights(os.path.join(\"..\", \"input\", \"airbusshipdetectionmodels\", \"segmentation_model.h5\"))\nelse:\n    while True:\n        loss_history = fit()\n        if np.min([mh.history['val_loss'] for mh in loss_history]) < -0.2:\n            break\n\n    plot_model_fitting_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Prediction & Evaluation","metadata":{}},{"cell_type":"code","source":"test_generator = random_data_generator(df_test.reset_index(), \n                                  get_X= lambda row: np.array(get_preprocessed_image(row, dimension=IMG_DIMENSION)),\n                                  get_y= lambda row: np.array(get_mask_as_image(row, dimension=IMG_DIMENSION)),\n                                  batch_size = 1000)\n\nX_test, y_test = next(test_generator)\ny_pred_seg = seg_model.predict(X_test)\ny_pred_bin = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(X_test[0:24], np.array(y_test[0:24]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(X_test[0:24], np.array(y_pred_seg[0:24,:,:,0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 12 # Compare just one image\nplot_images([X_test[i],X_test[i]], np.array([y_test[i], y_pred_seg[i,:,:,0]]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scoring","metadata":{}},{"cell_type":"code","source":"def score(y_test, y_pred):\n    pred = y_pred[:,:,:,0] if y_pred.ndim == 4 else y_pred\n    pred = (pred > 0.5).astype(float)\n    score = 0\n\n    for i in range(y_test.shape[0]):\n        score += fbeta_score(y_test[i].flatten(), pred[i].flatten(), beta=2, zero_division=1)\n    return score / y_test.shape[0]\n\ndef ensemble_score(y_test, y_pred_seg, y_pred_bin):\n    y_pred = []\n    y_pred_bin = np.argmax(y_pred_bin, axis=1)\n    for i in range(y_pred_seg.shape[0]):\n        if y_pred_bin[i] == 1:\n            y_pred += [y_pred_seg[i]]\n        else:\n            y_pred += [np.zeros((y_pred_seg.shape[1], y_pred_seg.shape[2], 1))]\n    return score(y_test, np.array(y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"FBeta Score: \", score(y_test, y_pred_seg))\nprint(\"FBeta Score with Ensemble:\", ensemble_score(y_test, y_pred_seg, y_pred_bin))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}